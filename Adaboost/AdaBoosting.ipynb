{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VM 0 starts running at 0\n",
      "VM 0 finishes at 10\n",
      "VM 1 starts running at 19.968894517379248\n",
      "VM 1 finishes at 27.968894517379248\n",
      "VM 2 starts running at 44.31154261212738\n"
     ]
    }
   ],
   "source": [
    "import simpy\n",
    "import random\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class Datacenter:\n",
    "    def __init__(self, env, num_hosts):\n",
    "        self.env = env\n",
    "        self.hosts = [simpy.Resource(env, capacity=1) for _ in range(num_hosts)]\n",
    "\n",
    "    def process_vm_request(self, vm, prediction_model):\n",
    "        host = self.get_best_host(prediction_model)\n",
    "        with host.request() as req:\n",
    "            yield req\n",
    "            print(f\"VM {vm.id} starts running at {self.env.now}\")\n",
    "            yield self.env.timeout(vm.runtime)\n",
    "            print(f\"VM {vm.id} finishes at {self.env.now}\")\n",
    "\n",
    "    def get_best_host(self, prediction_model):\n",
    "        # Simulate selecting the best host based on predictions from the model\n",
    "        # For simplicity, let's assume random selection for demonstration\n",
    "        return random.choice(self.hosts)\n",
    "\n",
    "class VirtualMachine:\n",
    "    id_counter = 0\n",
    "    def __init__(self, env, runtime):\n",
    "        self.id = VirtualMachine.id_counter\n",
    "        VirtualMachine.id_counter += 1\n",
    "        self.env = env\n",
    "        self.runtime = runtime\n",
    "\n",
    "def generate_workload(env, datacenter, prediction_model):\n",
    "    while True:\n",
    "        vm = VirtualMachine(env, runtime=random.randint(5, 15))\n",
    "        yield env.process(datacenter.process_vm_request(vm, prediction_model))\n",
    "        yield env.timeout(random.expovariate(1/10))  # Generate inter-arrival time for new VMs\n",
    "\n",
    "def train_prediction_model(history_data):\n",
    "    # Train an AdaBoost classifier using historical data\n",
    "    # For simplicity, let's assume a simple decision tree classifier\n",
    "    base_classifier = DecisionTreeClassifier(max_depth=1)\n",
    "    ada_boost = AdaBoostClassifier(base_classifier, n_estimators=50)\n",
    "    # Training the model with historical data\n",
    "    # You need to prepare your historical data for training here\n",
    "    ada_boost.fit(history_data[\"features\"], history_data[\"labels\"])\n",
    "    return ada_boost\n",
    "\n",
    "# Simulation environment setup\n",
    "env = simpy.Environment()\n",
    "datacenter = Datacenter(env, num_hosts=3)\n",
    "\n",
    "# Generate historical data (features and labels)\n",
    "# You need to replace this with actual historical data preparation\n",
    "# For demonstration, let's generate random historical data\n",
    "history_data = {\n",
    "    \"features\": [[random.uniform(0, 1) for _ in range(10)] for _ in range(100)],\n",
    "    \"labels\": [random.choice([0, 1]) for _ in range(100)]\n",
    "}\n",
    "\n",
    "# Train the prediction model using historical data\n",
    "prediction_model = train_prediction_model(history_data)\n",
    "\n",
    "# Run simulation\n",
    "env.process(generate_workload(env, datacenter, prediction_model))\n",
    "env.run(until=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    We've extended the Datacenter class to incorporate the prediction model for selecting the best host.\n",
    "    The get_best_host method simulates the selection of the best host based on predictions from the model. In a real scenario, this would involve using predictions generated by the AdaBoost model to choose the most suitable host for running a VM.\n",
    "    We've added a train_prediction_model function to train an AdaBoost classifier using historical data. This function would typically train the model on features extracted from historical data and their corresponding labels.\n",
    "    The generate_workload function now accepts the prediction model as an argument and uses it to make predictions when processing VM requests."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
